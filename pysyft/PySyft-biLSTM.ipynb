{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity recognition with federated learning \n",
    "Simple example in implementing a biLSTM model for NER, using PyTorch and PySyft. \n",
    "\n",
    "* Due to an ongoing issue with recurrent layers on PySyft (on the roadmap to be fixed!) we use a vanilla biLSTM implemented 'from scratch'. \n",
    "    * To replicate the issue, see: https://github.com/j-chim/nlp-examples/blob/pysyft-ner/pysyft/minimal-example.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import torch \n",
    "from tqdm.notebook import tqdm\n",
    "import syft as sy\n",
    "\n",
    "import torch.nn as nn\n",
    "#from syft.frameworks.torch.nn import LSTM\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Define filepaths and selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # Data and path\n",
    "    train_path = \"./data/eng.train\",\n",
    "    embeddings_path = \"./data/glove.840B.300d.txt\", \n",
    "    pad_token = \"<PAD>\",\n",
    "    unk_token = \"<UNK>\",\n",
    "    batch_size=32,\n",
    "    \n",
    "    # Model \n",
    "    embedding_dim = 300,\n",
    "    lstm_dim = 56,\n",
    "    \n",
    "    # Training\n",
    "    seed=42,\n",
    "    num_epochs=30,\n",
    "    lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1295e54b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Setup PySyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "carol = sy.VirtualWorker(hook, id=\"carol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Prepare data\n",
    "CoNLL 2003: https://www.clips.uantwerpen.be/conll2003/ner/\n",
    "* This notebook only uses the English data.\n",
    "* The raw data are a series of text files.\n",
    "    * Each line looks like this: \"EU NNP I-NP I-ORG\"\n",
    "    * Here we are only interested in the actual word (\"EU\") and the NER tag (\"I-ORG\")\n",
    "* Process raw file into tensors, then into federated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentences(filepath, is_cased=True):\n",
    "    \"\"\" Process data in the CoNLL-2003 format into words/labels per sentence. \"\"\"\n",
    "    sents, labels = [], []\n",
    "    curr_sent_words, curr_sent_labels = [], []\n",
    "    with open(filepath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        if not is_cased:\n",
    "            line = line.lower()\n",
    "        if line == \"\\n\":\n",
    "            sents.append(curr_sent_words)\n",
    "            labels.append(curr_sent_labels)\n",
    "            curr_sent_words, curr_sent_labels = [], []\n",
    "        else:\n",
    "            elements = line.strip().split(\" \")\n",
    "            word = elements[0]\n",
    "            label = elements[-1]\n",
    "            curr_sent_words.append(word)\n",
    "            curr_sent_labels.append(label)\n",
    "    \n",
    "    return sents, labels\n",
    "\n",
    "\n",
    "def process_data(sents, labels, word2id, label2id, max_length, pad_token, unknown_token,\n",
    "                 is_train=True):\n",
    "    \"\"\" Processes data in the CoNLL 2003 format into torch tensors.\n",
    "    \n",
    "    Args:\n",
    "      sents:         List of sentences (each a list of words)\n",
    "      labels:        List of list of labels \n",
    "      word2id:       Dictionary mapping words to int indices\n",
    "      label2id:      Dictionary mapping labels to int indices\n",
    "      max_length:    Target length that we want to pad sequences to.\n",
    "      pad_token:     String for padding.\n",
    "      unknown_token: String to replace OOV words.      \n",
    "      is_train:      Is processing for training data or not. \n",
    "                     If true, updates the dictionaries with each value.\n",
    "                     If false, unseen words will be mapped to <UNK>.\n",
    "    \n",
    "    Returns:\n",
    "      word2id:       Word-to-indices mapping. If is_train, it will be updatd.\n",
    "      label2id:      Label-to-indices mapping. If is_train, it will be updated. \n",
    "      X:             Tensor of processed sentences.\n",
    "      y:             Tensor of processed labels.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    if is_train:\n",
    "        pad_id, unk_id = 0, 1\n",
    "        word2id[pad_token] = pad_id\n",
    "        label2id[pad_token] = pad_id\n",
    "        word2id[unknown_token] = unk_id\n",
    "    else:\n",
    "        pad_id = word2id[pad_token]\n",
    "        unk_id = word2id[unknown_token]\n",
    "    \n",
    "    for i, sent in enumerate(sents):\n",
    "        X_i, y_i = [], []\n",
    "        curr_labels = labels[i]\n",
    "        sent = sent[:max_length]\n",
    "        diff = max_length - len(sent)\n",
    "        for word, label in zip(sent, curr_labels):\n",
    "            if is_train:\n",
    "                # If preparing training data, update mappings as we go\n",
    "                word_id = word2id.get(word, None)\n",
    "                if not word_id:\n",
    "                    word_id = len(word2id)\n",
    "                    word2id[word] = word_id\n",
    "                \n",
    "                label_id = label2id.get(label, None)\n",
    "                if not label_id:\n",
    "                    label_id = len(label2id)\n",
    "                    label2id[label] = label_id\n",
    "            else:\n",
    "                # Otherwise, fetch id from existing mappings\n",
    "                word_id = word2id.get(word, word2id[unknown_token])\n",
    "                label_id = label2id.get(label)\n",
    "                if not label_id:\n",
    "                    raise LookupError(f'Unseen label {label}')\n",
    "            X_i.append(word_id)\n",
    "            y_i.append(label_id) \n",
    "            \n",
    "        # Pad sequences to max length\n",
    "        X_i.extend([pad_id] * diff)\n",
    "        y_i.extend([pad_id] * diff)\n",
    "        \n",
    "        X.append(X_i)\n",
    "        y.append(y_i)\n",
    "            \n",
    "    X = torch.tensor(X)   \n",
    "    y = torch.tensor(y)\n",
    "    \n",
    "    return word2id, label2id, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, labels = extract_sentences(args.train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get maximum sequence length based on loaded sentences\n",
    "max_train_sent_length = max(len(sent) for sent in sents)\n",
    "max_length = 2**math.ceil(math.log2(max_train_sent_length))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id, label2id = dict(), dict()\n",
    "word2id, label2id, X, y = process_data(\n",
    "    sents=sents, labels=labels, word2id=word2id, label2id=label2id, \n",
    "    max_length=max_length, pad_token=args.pad_token, unknown_token=args.unk_token\n",
    ")\n",
    "vocab_size = len(word2id)\n",
    "num_labels = len(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {v:k for k, v in word2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14986, 128]), torch.Size([14986, 128]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now transform this into PySyft's federated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = sy.BaseDataset(X[:1000], y[:1000]) # TODO: Run on full dataset.\n",
    "dataset = base.federate((alice, bob))\n",
    "train_loader = sy.FederatedDataLoader(\n",
    "    federated_dataset=dataset, \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=True                     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed words\n",
    "* Pre-trained word embeddings. Here we use common crawl glove cased, 840B/300d. \n",
    "    * Source: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pretrained_embeddings = True\n",
    "if use_pretrained_embeddings:\n",
    "    word2vec_path = './word2vec.pkl'\n",
    "    if os.path.exists(word2vec_path):\n",
    "        with open(word2vec_path, 'rb') as f:\n",
    "            word2vec = pickle.load(f)\n",
    "    else:\n",
    "        word2vec = dict()\n",
    "        with open(args.embeddings_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in tqdm(lines):        \n",
    "            split_line = line.split(\" \")\n",
    "            word = split_line[0]\n",
    "            vec = torch.tensor([float(v) for v in split_line[1:]])\n",
    "\n",
    "            word2vec[word] = vec\n",
    "        word2vec[args.unk_token] = torch.randn(300)\n",
    "        #word2vec[args.unk_token] = torch.mean(, axis=0) # TODO: replace with mean\n",
    "        with open(word2vec_path, 'wb') as f:\n",
    "            pickle.dump(word2vec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032e95e2d191496aac9211740b1c6290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2196017.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = torch.zeros((vocab_size, args.embedding_dim))\n",
    "for w, v in tqdm(word2vec.items()): # can prob change to id2vec\n",
    "    idx = word2id.get(w, word2id[args.unk_token])\n",
    "    pretrained_embeddings[idx,:] = v    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\" Vanilla LSTM.\n",
    "    Adapted from: https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, batch_first=True, \n",
    "                 bidirectional=True):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            input_size:    input vector size.\n",
    "            hidden_size:   hidden state dimension.\n",
    "            batch_first:   whether first dimension of inputs is batch_size.\n",
    "            bidirectional: whether to run model in both directions.\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        # gate values computed using previous hidden state and current input\n",
    "        self.concat_size = self.hidden_size + input_size\n",
    "        \n",
    "         # forget gate\n",
    "        self.f_t = nn.Linear(self.concat_size, self.hidden_size)\n",
    "        self.sigmoid_f = nn.Sigmoid()\n",
    "        \n",
    "        # input gate\n",
    "        self.i_t = nn.Linear(self.concat_size, self.hidden_size)\n",
    "        self.sigmoid_i = nn.Sigmoid()\n",
    "        \n",
    "        # output gate\n",
    "        self.o_t = nn.Linear(self.concat_size, self.hidden_size)\n",
    "        self.sigmoid_o = nn.Sigmoid()\n",
    "        \n",
    "        # candidate cell state\n",
    "        self.c_tilde = nn.Linear(self.concat_size, self.hidden_size)\n",
    "        self.tanh_cell = nn.Tanh()\n",
    "        \n",
    "        self.tanh_hidden = nn.Tanh()\n",
    "        \n",
    "    def init_states(self, x, batch_size):\n",
    "        zeros = torch.zeros(batch_size,\n",
    "                            self.hidden_size,\n",
    "                            dtype=x.dtype, \n",
    "                            device=x.device)\n",
    "        location = x.location\n",
    "        if location is not None:\n",
    "            return (zeros.send(location), zeros.send(location))\n",
    "        return (zeros, zeros)\n",
    "    \n",
    "    def _pass(self, batch_size, x, prev_h, prev_c):\n",
    "        concatenated = torch.cat((prev_h, x), -1)\n",
    "\n",
    "        input_gate = self.sigmoid_i(self.i_t(concatenated))\n",
    "        forget_gate = self.sigmoid_f(self.f_t(concatenated))\n",
    "        output_gate = self.sigmoid_o(self.o_t(concatenated))\n",
    "\n",
    "        c_tilde = self.tanh_cell(self.c_tilde(concatenated))\n",
    "        cell_state = (forget_gate * prev_c) + (input_gate * c_tilde)\n",
    "        \n",
    "        hidden = output_gate * self.tanh_hidden(cell_state)\n",
    "    \n",
    "        return (hidden, cell_state)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, prev_hidden=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x:              input tensor (batch_size, seq_size, feat_size) \n",
    "            prev_hidden:    tuple of initial/previous hidden state and cell state.\n",
    "                            Defaults to zero. \n",
    "        Returns:\n",
    "            hidden:         LSTM hidden state (batch_size, seq_size, hidden_size)\n",
    "            cell_state:     LSTM cell state \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.batch_first:\n",
    "            batch_size, seq_size, feat_size = x.shape\n",
    "        else:\n",
    "            seq_size, batch_size, feat_size = x.shape\n",
    "            x = x.permute(1, 0, 2)             \n",
    "        \n",
    "        if prev_hidden is None:\n",
    "            prev_h, prev_c = self.init_states(x, batch_size)\n",
    "        else:\n",
    "            prev_h, prev_c = prev_hidden\n",
    "        \n",
    "        h_forward, h_backward = [], []\n",
    "        c_forward, c_backward = [], [] \n",
    "        h_0, c_0 = prev_h, prev_c\n",
    "        \n",
    "        for t in range(seq_size):\n",
    "            x_t = x[:,t,:]\n",
    "            prev_h, prev_c = self._pass(batch_size, x_t, prev_h, prev_c)\n",
    "            h_forward.append(prev_h)\n",
    "            c_forward.append(prev_c)\n",
    "            \n",
    "        if self.bidirectional:\n",
    "            prev_h, prev_c = h_0, c_0\n",
    "            for t in reversed(range(seq_size)):\n",
    "                x_t = x[:,t,:]\n",
    "                prev_h, prev_c = self._pass(batch_size, x_t, prev_h, prev_c)\n",
    "                h_backward.append(prev_h)\n",
    "                c_backward.append(prev_c)\n",
    "            \n",
    "            h = torch.cat((torch.stack(h_forward), torch.stack(h_backward)), -1)\n",
    "            c = torch.cat((torch.stack(c_forward), torch.stack(c_backward)), -1)\n",
    "        else:\n",
    "            h = torch.stack(h_forward)\n",
    "            c = torch.stack(c_forward)\n",
    "            \n",
    "        return (h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LSTM implemented above and combine with embedding + linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tagger(nn.Module):\n",
    "    \"\"\" biLSTM for sequence tagging. \"\"\"\n",
    "    \n",
    "    def __init__(self, args, vocab_size, num_labels, \n",
    "                 pretrained_embeddings=None, batch_first=True, padding_idx=0):\n",
    "        \"\"\" \n",
    "        Args:\n",
    "            args:                  namespace object containing configs.\n",
    "            vocab_size:            number of unique words in training set. \n",
    "            num_labels:            number of output labels.\n",
    "            pretrained_embeddings: pretrained word embedding weights.\n",
    "                                   If None, weights will initialise randomly.\n",
    "            batch_first:           whether first dimension of inputs is batch_size.\n",
    "            padding_idx:           id corresponding to <PAD> tokens.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Tagger, self).__init__()\n",
    "        self.batch_first = batch_first\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = args.embedding_dim\n",
    "        self.lstm_hidden_size = args.lstm_dim\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                pretrained_embeddings\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                num_embeddings=self.vocab_size,\n",
    "                embedding_dim=self.embedding_size, \n",
    "                padding_idx=padding_idx            \n",
    "            )\n",
    "        \n",
    "        self.lstm = LSTM(\n",
    "            input_size=self.embedding_size,\n",
    "            hidden_size=self.lstm_hidden_size,\n",
    "            batch_first=self.batch_first,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            in_features=self.lstm_hidden_size*2,  # bidirectional \n",
    "            out_features=self.num_labels\n",
    "        ) \n",
    "        \n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "                    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.batch_first:\n",
    "            batch_size, seq_len = x.shape\n",
    "        else:\n",
    "            seq_len, batch_size = x.shape\n",
    "            x = x.permute(1, 0)\n",
    "            \n",
    "        embedded = self.embedding(x)\n",
    "        h, c = self.lstm(embedded)\n",
    "        y_out = self.fc(h)\n",
    "        \n",
    "        new_feat_size = y_out.shape[-1]\n",
    "        y_out = y_out.view(batch_size, new_feat_size, seq_len) \n",
    "        logits = self.log_softmax(y_out)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Tagger(args=args, vocab_size=len(word2id), num_labels=len(label2id))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizers = { \n",
    "    worker: optim.Adam(params=model.parameters(),lr=args.lr) \n",
    "    for worker in dataset.workers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(bob) training loss: 155.29152965545654\n",
      "(bob) training loss: 155.29092264175415\n",
      "(bob) training loss: 155.29072618484497\n",
      "(bob) training loss: 155.28915214538574\n",
      "(bob) training loss: 155.2884955406189\n",
      "(bob) training loss: 155.28441667556763\n",
      "(bob) training loss: 155.28483724594116\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(args.num_epochs):\n",
    "    training_loss = 0\n",
    "    \n",
    "    for data, label in train_loader: \n",
    "        worker = data.location.id\n",
    "        model.send(worker)\n",
    "\n",
    "        optimizers[worker].zero_grad()\n",
    "        log_probs = model(data)\n",
    "        loss = criterion(log_probs, label.squeeze())\n",
    "        loss.backward()\n",
    "        optimizers[worker].step()\n",
    "\n",
    "        model.get()\n",
    "        \n",
    "        curr_loss = loss.get().item()\n",
    "        training_loss += curr_loss\n",
    "    else:\n",
    "        print(f\"({worker}) training loss: {training_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
